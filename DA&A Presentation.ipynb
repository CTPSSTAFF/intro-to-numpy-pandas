{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2fdedf4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Before anything, let's import our libraries\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9988ebbf",
   "metadata": {},
   "source": [
    "# An Introduction to NumPy and Pandas\n",
    "Tanner Bonner | January 2023"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "afb8b97e",
   "metadata": {},
   "source": [
    "# What is NumPy?\n",
    "Read more at https://numpy.org/doc/stable/user/whatisnumpy.html\n",
    "### Summary from their website\n",
    "“NumPy is the fundamental package for scientific computing in Python. It is a Python library that provides a multidimensional array object, various derived objects (such as masked arrays and matrices), and an assortment of routines for fast operations on arrays, including mathematical, logical, shape manipulation, sorting, selecting, I/O, basic linear algebra, basic statistical operations, random simulation and much more.”\n",
    "### Fundamental object: the ndarray (\"NumPy array\")\n",
    "A list (+ of lists of lists…) sort of object. Some key components of ndarray versus a typical Python list:\n",
    "* All elements are the same data type, and thus the same size in memory\n",
    " * e.g. can't mix strings and integers together, unlike Python lists\n",
    "* Fixed size in memory at creation, thus consuming less memory to store data\n",
    " * unlike Python lists, which follow a dynamic array model, leaving extra space at creation to grow/shrink as needed\n",
    " \n",
    "### The significance of NumPy arrays\n",
    "* Facilitates operations on large numbers of data more efficiently and with less code than typical Python\n",
    " * Allows “vectorized code” - no explicit looping or indexing, which happens behind the scenes in optimized, pre-compiled C code.\n",
    " * Easier to read, fewer lines of code, and more closely resembles mathematical notation\n",
    "* Many scientific and mathematical Python libraries are built upon NumPy arrays, converting Python lists to NumPy arrays in pre-processing and outputting NumPy arrays\n",
    "\n",
    "An interesting quote: “One needs to know how to use NumPy arrays to efficiently use much of today’s scientific/mathematical Python-based software.\" Only knowing how to use Python’s built-in sequence types is deemed “insufficient” in the world of Python big data processing to achieve reasonable runtimes and memory usage."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e142a76f",
   "metadata": {},
   "source": [
    "In this notebook, we'll explore only a portion of the functionality provided by NumPy, including:\n",
    "* Creating NumPy Arrays\n",
    "* Investigating Properties of NumPy Arrays\n",
    "* Arithmetic with NumPy Arrays\n",
    "* Indexing and Filtering NumPy Arrays\n",
    "* Basic Statistics with NumPy Arrays"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5aea699a",
   "metadata": {},
   "source": [
    "## Creating NumPy Arrays - Some General Mechanisms\n",
    "See more at https://numpy.org/doc/stable/user/basics.creation.html"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f2d67e12",
   "metadata": {},
   "source": [
    "#### 1: Conversion from Python structures (i.e. lists and tuples) - use np.array(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f90a230",
   "metadata": {},
   "source": [
    "From a list of integers:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09d9063c",
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_list = [1, 2, 3, 4]\n",
    "oned_array = np.array(sample_list)\n",
    "print(type(oned_array))\n",
    "oned_array"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "03e45ff8",
   "metadata": {},
   "source": [
    "From a list of strings, converting to integers with dtype=int:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f25aa324",
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_list_2 = ['1', '2', '3', '4']\n",
    "oned_array_2 = np.array(sample_list_2, dtype=int)\n",
    "oned_array_2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e3aa1eb8",
   "metadata": {},
   "source": [
    "From a list of strings, converting to decimal ('floating point') values:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56d3c8ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_list_3 = ['1.5', '2.0', '2.5', '3.0']\n",
    "oned_array_3 = np.array(sample_list_3, dtype=float)\n",
    "oned_array_3"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "276257d0",
   "metadata": {},
   "source": [
    "From a list of lists of integers (a '2D' array):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5a17150",
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_list_2 = [[1, 2], [3, 4]]\n",
    "twod_array = np.array(sample_list_2)\n",
    "twod_array"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe3fe0a4",
   "metadata": {},
   "source": [
    "From a tuple:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8aa51a61",
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_tuple = (1, 2, 3, 4)\n",
    "array_2 = np.array(sample_list)\n",
    "array_2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f03e073a",
   "metadata": {},
   "source": [
    "From a mixed data structure:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d09e1d51",
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_data = [(1,), (2,), (3,)]\n",
    "array_3 = np.array(sample_data)\n",
    "array_3"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3fe524af",
   "metadata": {},
   "source": [
    "#### 2: Intrinsic and general NumPy array creation functions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f3753b90",
   "metadata": {},
   "source": [
    "np.linspace(start, stop, num) - generate evenly spaced numbers (default floating point) within a specified range (inclusive)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e5cfea8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# E.g.: generate all integers from 1 to 10\n",
    "ex_1 = np.linspace(start=1, stop=10, num=10, dtype=int)\n",
    "ex_1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "75c9509c",
   "metadata": {},
   "source": [
    "np.arange(start, stop, step) - generate evenly spaced numbers, separated by a specified step, within a specified range (start, stop-1) (similar to Python's range() function, and unlike np.linspace())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb5dd38c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# e.g.: generate all even integers from 2 to 10 (note stop must be end + 1)\n",
    "ex_2 = np.arange(start=2, stop=11, step=2) \n",
    "ex_2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "128429a1",
   "metadata": {},
   "source": [
    "np.ones(size) - generate an array of ones (default floating point) of a specified length"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d3bef40",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# e.g.: generate ten 1s of integer value\n",
    "ex_3 = np.ones(10, dtype=int)\n",
    "ex_3"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b6b6af88",
   "metadata": {},
   "source": [
    "np.zeros(size) - generate an array of zeros (default floating point) of a specified length"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fff72c47",
   "metadata": {},
   "outputs": [],
   "source": [
    "# e.g.: generate ten 0s of integer value\n",
    "ex_4 = np.zeros(10, dtype=int)\n",
    "ex_4"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "83166080",
   "metadata": {},
   "source": [
    "np.random.randint(low, high, size) -  generate integers randomly (uniform distribution) from a range (start, stop-1) of a specified length"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "843c9842",
   "metadata": {},
   "outputs": [],
   "source": [
    "# e.g.: generate 10 integers between 1 and 5\n",
    "ex_5 = np.random.randint(low=1, high=6, size=10)\n",
    "ex_5"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "08720e0a",
   "metadata": {},
   "source": [
    "np.random.random_sample(size) - generate floats randomly (uniform) from the interval [0.0, 1.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba08d186",
   "metadata": {},
   "outputs": [],
   "source": [
    "# e.g.: generate 10 floats in the range [0.0, 1.0)\n",
    "ex_6 = np.random.random_sample(size=10)\n",
    "ex_6"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a94e30ef",
   "metadata": {},
   "source": [
    "#### 3: Replicating or joining existing NumPy arrays"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ebe33eb2",
   "metadata": {},
   "source": [
    "Replicating from indexing:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b61191b",
   "metadata": {},
   "outputs": [],
   "source": [
    "ex_7 = np.array([1, 2, 3, 4])\n",
    "ex_8 = ex_7[:]\n",
    "ex_8"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "98da8fbc",
   "metadata": {},
   "source": [
    "Concatenating/joining using np.block([]):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf729f8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# e.g. join array ex_8 to the end of ex_7\n",
    "ex_9 = np.block([ex_7, ex_8]) # Note list input and order\n",
    "ex_9"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0aeae072",
   "metadata": {},
   "source": [
    "#### 4: Reading arrays from disk"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aace4d4f",
   "metadata": {},
   "source": [
    "Common method is to use np.genfromtxt(filename, delimiter, dtype). Another method is np.loadfromtxt(filename, delimiter, dtype), but np.genfromtxt provides additional functionality (such as missing_values, filling_values params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e4ffbd8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from_csv = np.genfromtxt(\"sample-data.csv\", delimiter=\",\", dtype=float)\n",
    "from_csv"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb715c6f",
   "metadata": {},
   "source": [
    "Small caveat: make sure your .CSV file is UTF-8 and not UTF-8-BOM (which might be generated by Excel) - if it is UTF-8-BOM, the first element will be \"na\" instead of the desired value. You can change this by opening the .CSV in Notepad++."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8da4c622",
   "metadata": {},
   "source": [
    "## Investigating Properties of NumPy Arrays"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "94c7f79a",
   "metadata": {},
   "source": [
    ".shape - returns a tuple specifying the size along each array dimension"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56abef22",
   "metadata": {},
   "outputs": [],
   "source": [
    "# .shape - the size along each array dimension; returns a tuple\n",
    "from_csv.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20c20649",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_entries = from_csv.shape[0]\n",
    "num_entries"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5224e5d1",
   "metadata": {},
   "source": [
    ".ndim - the number of dimensions of the array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3ed59c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# .ndim - the number of dimensions of the array\n",
    "from_csv.ndim"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "538cbbc3",
   "metadata": {},
   "source": [
    "## Arithmetic with NumPy Arrays"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "66b05e3f",
   "metadata": {},
   "source": [
    "In typical Python, to add a number to an entire list or to multiply an entire list by a value, you must iterate through and replace all of the values as shown below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4e4087a",
   "metadata": {},
   "outputs": [],
   "source": [
    "example_list = [1, 2, 3, 4]\n",
    "add_by = 1\n",
    "for i in range(len(example_list)):\n",
    "    example_list[i] += add_by\n",
    "example_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1779eb33",
   "metadata": {},
   "outputs": [],
   "source": [
    "multiply_by = 3\n",
    "for i in range(len(example_list)):\n",
    "    example_list[i] *= multiply_by\n",
    "example_list"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "619619df",
   "metadata": {},
   "source": [
    "Using NumPy, you can do these operations in one line."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09375a12",
   "metadata": {},
   "outputs": [],
   "source": [
    "example_list = [1, 2, 3, 4]\n",
    "add = 1\n",
    "ex_array = np.array(example_list)\n",
    "ex_array = ex_array + add\n",
    "ex_array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3176836a",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "multiply = 3\n",
    "ex_array = ex_array * multiply\n",
    "ex_array"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ccc909a2",
   "metadata": {},
   "source": [
    "You can also do element-wise arithmetic between two arrays much easier. In typical Python, it would look like this:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b637fa93",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "example_list = [1, 2, 3, 4]\n",
    "example_list_2 = [3, 4, 5, 6]\n",
    "example_list_3 = []\n",
    "for i in range(len(example_list_2)):\n",
    "    example_list_3.append(example_list[i]+example_list_2[i])\n",
    "example_list_3"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ac73aaf",
   "metadata": {},
   "source": [
    "Using NumPy, the for loop and indexing is simplified into a single operation:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79d68111",
   "metadata": {},
   "outputs": [],
   "source": [
    "ex_array = np.array([1, 2, 3, 4])\n",
    "ex_array_2 = np.array([3, 4, 5, 6])\n",
    "ex_array_3 = ex_array + ex_array_2\n",
    "ex_array_3"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "59aff4c8",
   "metadata": {},
   "source": [
    "## Indexing and Filtering NumPy Arrays"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be427f33",
   "metadata": {},
   "source": [
    "Splicing - [start:stop:step] - works similarly to Python lists"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26541a14",
   "metadata": {},
   "outputs": [],
   "source": [
    "ex_array = np.array([1, 2, 3, 4, 5, 6])\n",
    "# e.g. retrieve the third and fourth elements\n",
    "ex_array[2:4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97d9c58c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# e.g. retrieve the first, third, and fifth elements\n",
    "ex_array[0:6:2] "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c12968a",
   "metadata": {},
   "source": [
    "Filter based on conditional \"true/false\" evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5891349",
   "metadata": {},
   "outputs": [],
   "source": [
    "# e.g. retrieve all values greater than or equal to 4\n",
    "ex_array[ex_array >= 4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8f73d85",
   "metadata": {},
   "outputs": [],
   "source": [
    "# e.g. retrieve all values greater than 1 but less than 4\n",
    "ex_array[(ex_array > 1) & (ex_array < 4)] # use \"&\" for \"and\" and \"|\" for \"or\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3aae756",
   "metadata": {},
   "outputs": [],
   "source": [
    "# e.g. retrieve all values less than 2 or greater than 4\n",
    "ex_array[(ex_array < 2) | (ex_array > 4)]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "404eab1a",
   "metadata": {},
   "source": [
    "## Basic Statistics with NumPy Arrays"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "934e4fe7",
   "metadata": {},
   "source": [
    "NumPy array methods - min() and max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55d25eaa",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "ex_array = np.array([1, 4, 6, 3, 5, 3, 7, 3, 2, 1, 3, 2])\n",
    "print(\"Minimum: \" + str(ex_array.min()))\n",
    "print(\"Maximum: \" + str(ex_array.max()))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "76773aa8",
   "metadata": {},
   "source": [
    "NumPy functions - np.percentile(arr, percent), np.median(arr), np.mean(arr), np.std(arr), np.var(arr), np.sum(arr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "917c9b4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "print('1st Quartile: ' + str(np.percentile(ex_array, 25)))\n",
    "print('Median: ' + str(np.median(ex_array)))\n",
    "print('Mean: ' + str(np.mean(ex_array)))\n",
    "print('Standard Deviation: ' + str(np.std(ex_array)))\n",
    "print('Variance: ' + str(np.var(ex_array)))\n",
    "print('Sum of Values: ' + str(np.sum(ex_array)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "001b9354",
   "metadata": {},
   "source": [
    "# What is Pandas?\n",
    "Read more at https://en.wikipedia.org/wiki/Pandas_(software) \n",
    "### Summary from Wikipedia\n",
    "Pandas is a Python library for data manipulation and analysis, offering data structures and operations for manipulating tables and time series data. Its name is a play on the phrase \"Python data analysis\" and is derived from the term \"panel data\" - an econometrics term for data sets that include observations over multiple periods for the same individuals. It is built upon the NumPy library.\n",
    "\n",
    "### Fundamental object: the DataFrame\n",
    "The DataFrame represents a two-dimensional data table (\"tabular\" data) with rows that have a given 'index' (or identifier), and columns. Columns can be different data types from eachother. Think of DataFrames as spreadsheets with a fixed number of rows and columns, where each row represents an \"entry\" of the data set, and each column specifies some sort of variable or attribute (if the dataset is tidy as-is).\n",
    "\n",
    "### The significance of Pandas\n",
    "Similarly to NumPy, there are many operational benefits to using Pandas as a tool for data analysis versus typical Python. Along with benefits stemming from optimization, there are a suite of tools that allow one to parse and clean data sets in an easy way. A few of the benefits are listed below:\n",
    "* Many inbuilt methods available for fast data manipulation made possible with vectorisation\n",
    "* Data alignment and integrated handling of missing data\n",
    "* Label-based slicing, fancy indexing, and subsetting of large datasets\n",
    "* Data structure column insertion and deletion\n",
    "* Data set merging and joining\n",
    "* Data filtration\n",
    "* Data filling\n",
    "* Statistical analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c78d020",
   "metadata": {},
   "source": [
    "In the examples below, we'll start with a basic DataFrame and then take a look at Freight Analysis Framework 5 data for 2017 and 2050, downloaded from https://faf.ornl.gov/faf5/dtt_total.aspx. The portions of Pandas functionality that we'll explore in this notebook includes:\n",
    "* Creating a DataFrame\n",
    "* Investigating Properties of DataFrames\n",
    "* Organizing and Cleaning Data in DataFrames\n",
    "* Sorting, Iterating, and Aggregation in DataFrames"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17f1a793",
   "metadata": {},
   "source": [
    "## Creating a DataFrame - Some General Mechanisms"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c8fdf5c",
   "metadata": {},
   "source": [
    "#### 1: Conversion from Python data structures - primary method: pd.DataFrame(data, index, columns) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "42e33e6b",
   "metadata": {},
   "source": [
    "From a list:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87fabe35",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "names = ['Tanner', 'Rose', 'Joe', 'Sophie']\n",
    "df = pd.DataFrame(names, columns=['first_name'])\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35bf0dd5",
   "metadata": {},
   "source": [
    "From a dictionary containing aligned lists -  keys = columns, lists with entries = rows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24e00705",
   "metadata": {},
   "outputs": [],
   "source": [
    "people = { 'first_name': names, \n",
    "          'last_name': ['Bonner', 'McCarron', 'Delorto', 'Fox'], \n",
    "          'role': ['Analyst', 'Manager', 'Analyst', 'Analyst']}\n",
    "df = pd.DataFrame(people)\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "07c253f9",
   "metadata": {},
   "source": [
    "#### 2: Reading tables from disk"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd45d745",
   "metadata": {},
   "source": [
    "Some options include pd.read_csv(filename) and pd.read_excel(filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc73a392",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "faf_data = pd.read_csv('faf-numpy-pandas-testing.csv')\n",
    "faf_data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b97c393f",
   "metadata": {},
   "source": [
    "## Investigating Properties of DataFrames"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "568ca6c6",
   "metadata": {},
   "source": [
    ".head(num_rows) will print out the first num_rows of a DataFrame (by default, num_rows is 5)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2aa13ea",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "faf_data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b05037ac",
   "metadata": {},
   "source": [
    ".columns returns a list of all of the column names of the DataFrame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97037073",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Get # of columns and all of the column names\n",
    "print('Number of columns: ' + str(len(faf_data.columns)))\n",
    "print('Column names:')\n",
    "for column in faf_data.columns:\n",
    "    print(column)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d063667",
   "metadata": {},
   "source": [
    ".shape (recall from NumPy) returns a tuple of (rows, columns) for the DataFrame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7f3b60f",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(faf_data.shape)\n",
    "print(\"Number of Rows: \" + str(faf_data.shape[0]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d7e9e4c",
   "metadata": {},
   "source": [
    ".size returns the number of rows x columns (total data 'entries')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7233746",
   "metadata": {},
   "outputs": [],
   "source": [
    "faf_data.size"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c366166",
   "metadata": {},
   "source": [
    ".dtypes returns the data types of each column - note 'object' is string-like"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a82ba53",
   "metadata": {},
   "outputs": [],
   "source": [
    "faf_data.dtypes"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "53046545",
   "metadata": {},
   "source": [
    "## Organizing and Cleaning Data in DataFrames"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36c9bc5f",
   "metadata": {},
   "source": [
    "#### First, let's replace some of these column names with something more readable."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb9d0e36",
   "metadata": {},
   "source": [
    "We'll use the method df.rename(dict, inplace=True) where dict is a dictionary mapping original to new column names."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "07ed55a9",
   "metadata": {},
   "source": [
    "Most operations occur as a copy of the DataFrame, thus in most cases you must reassign the variable or specify 'inplace = True' when applicable."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "309be813",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Rename columns - provide a dictionary of original:new column names\n",
    "columns_rename = {\n",
    "    'dms_orig': 'Origin',\n",
    "    'dms_dest': 'Destination',\n",
    "    'sctg2': 'Commodity Type',\n",
    "    'dms_mode': 'Mode',\n",
    "    'thousand tons in 2017': 'Thousand Tons (2017)',\n",
    "    'thousand tons in 2050': 'Thousand Tons (2050)'\n",
    "}\n",
    "faf_data.rename(columns=columns_rename, inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8cf47313",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Much better!\n",
    "for column in faf_data.columns:\n",
    "    print(column)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d6dea6c",
   "metadata": {},
   "source": [
    "#### Now, let's check for any N/A values. To do this, we will use the df.isna() function, which will return a dataframe of True/False values for each data point in our dataframe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "415b794b",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "is_na = faf_data.isna()\n",
    "print(is_na)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d96ed31",
   "metadata": {},
   "source": [
    "We can do a column-by-column search of any N/A values as well, finding which entries have an N/A value by using filtering and .index to retrieve such indices where the condition is true."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6407d47",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "for column in faf_data.columns:\n",
    "    is_na_in_column = faf_data[column].isna()\n",
    "    print(faf_data[is_na_in_column == True].index)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5adecbfb",
   "metadata": {},
   "source": [
    "In this case, we have no N/A values (yay!)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf1b6312",
   "metadata": {},
   "source": [
    "#### Next, let's replace the 'Commodity Type' and 'Mode' columns to remove their original \"x[y]-\" prefixes. We will do this by mapping the original values to our desired values, similar to replacing the column names above."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a79ddad",
   "metadata": {},
   "source": [
    "First, we will get the unique values from the original column values. We'll do this by using the .unique() method on the column."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae660f3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "orig_comm_vals = faf_data[\"Commodity Type\"].unique()\n",
    "orig_comm_vals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56271929",
   "metadata": {},
   "outputs": [],
   "source": [
    "orig_mode_vals = faf_data[\"Mode\"].unique()\n",
    "orig_mode_vals"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "981a0651",
   "metadata": {},
   "source": [
    "Second, we will create lists of the replacement values, where each value is a sliced version of itself, removing the prefix as desired."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c429acc",
   "metadata": {},
   "outputs": [],
   "source": [
    "new_comm_vals = [val[3:] for val in orig_comm_vals] # Slicing off the prefix of each value\n",
    "new_comm_vals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75f92e5c",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "new_mode_vals = [val[2:] for val in orig_mode_vals] # Slicing off the prefix of each value\n",
    "new_mode_vals"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "479b6c0e",
   "metadata": {},
   "source": [
    "Next, we set up dictionaries mapping the original values to the replacement values. To help us do this, we'll use \"zip\" which pairs elements from distinct iterable data structures together."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "923fa7cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "comm_replace = { orig: new for orig, new in zip(orig_comm_vals, new_comm_vals)}\n",
    "comm_replace"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91859e7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "mode_replace = { orig: new for orig, new in zip(orig_mode_vals, new_mode_vals)}\n",
    "mode_replace"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b032fa15",
   "metadata": {},
   "source": [
    "Lastly, we replace the values in each column using our dictionary mappings that we created. We will use the form .replace(values), where values is a dictionary."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "323c581f",
   "metadata": {},
   "outputs": [],
   "source": [
    "faf_data['Commodity Type'] = faf_data['Commodity Type'].replace(comm_replace)\n",
    "faf_data['Mode'] = faf_data['Mode'].replace(mode_replace)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e74db4c9",
   "metadata": {},
   "source": [
    "Note: you could also use the following syntax with inplace=True to change the values. However, to be safe, it might be best to explicitly change the values per-column, as it could lead to unwanted results depending upon our data. \n",
    "* When might we have an unwanted result? (hint: it wouldn't happen with this dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e41d8bf1",
   "metadata": {},
   "outputs": [],
   "source": [
    "faf_data.replace(comm_replace, inplace=True)\n",
    "faf_data.replace(mode_replace, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39795476",
   "metadata": {},
   "source": [
    "Checking our results by looking at the value set in each of the replaced columns:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75c4d22b",
   "metadata": {},
   "outputs": [],
   "source": [
    "faf_data['Mode'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53923392",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "faf_data['Commodity Type'].unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7274670b",
   "metadata": {},
   "source": [
    "#### Let's create a new column in our DataFrame representing the difference in tons from 2017 to 2050. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "58896c33",
   "metadata": {},
   "source": [
    "To create a new column, we index on our new column name and assign its column-wise calculation as follows, where arithmetic is performed in a NumPy fashion."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d1b4be9",
   "metadata": {},
   "outputs": [],
   "source": [
    "faf_data['Difference in Tons (2017 to 2050)'] = (faf_data['Thousand Tons (2050)'] - faf_data['Thousand Tons (2017)']) * 1000"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "988c7b3e",
   "metadata": {},
   "source": [
    "#### We'd like to know more information specifically about freight movement via trucks. To start, we can create a new DataFrame with only entries where the 'Mode' is 'Truck'."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5abc142a",
   "metadata": {},
   "source": [
    "To filter, we'll index the DataFrame on the condition desired and make a copy using .copy() to prevent warnings from Pandas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84429252",
   "metadata": {},
   "outputs": [],
   "source": [
    "faf_trucks = faf_data[faf_data['Mode'] == 'Truck'].copy()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "610b1a8f",
   "metadata": {},
   "source": [
    "Checking our results by seeing all unique values for the 'Mode' column in our new DataFrame:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "efa712c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "faf_trucks['Mode'].unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "628f7dbc",
   "metadata": {},
   "source": [
    "So what's going on here? \n",
    "Recall how Pandas is built upon NumPy, and in NumPy, operations like arithmetic and comparisons are done element-wise across an entire array. By specifying \"faf_data['Mode'] == 'Truck'\", we retrieve a Pandas \"bool\" type, in this case a one-dimensional ordered list of True/False values over all of the entries from comparing its 'Mode' value to 'Truck'. This is then used to filter the DataFrame to retrieve only entries where the evaluation is True - that is, its 'Mode' is 'Truck'."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "edcbef3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(faf_data['Mode'] == 'Truck')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d1e781c1",
   "metadata": {},
   "source": [
    "#### Let's add some new columns to our DataFrame estimating the number of trucks for each year, 2017 and 2050. The FTA recommends a conversion factor of 20 tons per truck."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b969b236",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "faf_trucks['Trucks (2017)'] = (faf_trucks['Thousand Tons (2017)'] / 20) * 1000\n",
    "faf_trucks['Trucks (2050)'] = (faf_trucks['Thousand Tons (2050)'] / 20) * 1000\n",
    "faf_trucks.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff9b6dba",
   "metadata": {},
   "source": [
    "Now, it's somewhat awkward considering there might be \"469.120\" trucks. Let's change the data type of our trucks columns to be integers, rather than floats. We'll do this with the .astype() method."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01b687a7",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "faf_trucks['Trucks (2017)'] = faf_trucks['Trucks (2017)'].astype(int)\n",
    "faf_trucks['Trucks (2050)'] = faf_trucks['Trucks (2050)'].astype(int)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b0277d46",
   "metadata": {},
   "source": [
    "Checking our results with .dtypes:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd67093c",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "print(faf_trucks.dtypes)\n",
    "faf_trucks.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "38a0571d",
   "metadata": {},
   "source": [
    "Finally, let's create a column specifying the difference in estimated trucks from 2017 to 2050 and check that its the proper data type. Since we're only checking one column here, we'll use .dtype instead of .dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54ac2849",
   "metadata": {},
   "outputs": [],
   "source": [
    "faf_trucks['Difference in Trucks (2017 to 2050)'] = faf_trucks['Trucks (2050)'] - faf_trucks['Trucks (2017)']\n",
    "print(faf_trucks['Difference in Trucks (2017 to 2050)'].dtype)\n",
    "faf_trucks.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a66d69ae",
   "metadata": {},
   "source": [
    "## Sorting, Iterating, and Aggregation in DataFrames"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "43c4f8e5",
   "metadata": {},
   "source": [
    "#### Suppose we'd like to know the total trucks estimated for 2017 and 2050, and the total difference."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e102e6f",
   "metadata": {},
   "source": [
    "We can use the .sum() method to find this out."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "680c451f",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "total_trucks_2017 = faf_trucks['Trucks (2017)'].sum()\n",
    "print(\"Total Trucks (2017): \" + \"{:,}\".format(total_trucks_2017))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9870e4b3",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "total_trucks_2050 = faf_trucks['Trucks (2050)'].sum()\n",
    "print(\"Total Trucks (2050): \" + \"{:,}\".format(total_trucks_2050))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1258c2f",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "total_difference_2017_2050 = faf_trucks['Difference in Trucks (2017 to 2050)'].sum()\n",
    "print(\"Difference in Trucks (2017 to 2050): \" + \"{:,}\".format(total_difference_2017_2050))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "41537e8c",
   "metadata": {},
   "source": [
    "#### Suppose we want to know the top 10 commodity types for difference in trucks from 2017 to 2050, at both the lowest and highest extremes."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f3945f3b",
   "metadata": {},
   "source": [
    "To find this out, we can use the .sort_values() method, indexing, and iterating through the entries using the .iterrows() method. .iterrows() returns an iterable of index, entry pairings."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90e2573c",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Slicing for first 10 entries with [:10]\n",
    "bot_10_difference = faf_trucks.sort_values(by='Difference in Trucks (2017 to 2050)', ascending=True)[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8db503ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Bottom 10 Differences in Trucks from 2017 to 2050 by Commodity Type\")\n",
    "for index, entry in bot_10_difference.iterrows():\n",
    "    print(entry['Commodity Type'] + \", \" + \"{:,}\".format(entry['Difference in Trucks (2017 to 2050)']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f678c50",
   "metadata": {},
   "outputs": [],
   "source": [
    "top_10_difference = faf_trucks.sort_values(by='Difference in Trucks (2017 to 2050)', ascending=False)[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "420756a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Top 10 Differences in Trucks from 2017 to 2050 by Commodity Type\")\n",
    "for index, entry in top_10_difference.iterrows():\n",
    "    print(entry['Commodity Type'] + \", \" + \"{:,}\".format(entry['Difference in Trucks (2017 to 2050)']))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "29ebd7f2",
   "metadata": {},
   "source": [
    "#### Let's find out what commodity types and modes have the largest total differences in tons from 2017 to 2050."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3698c831",
   "metadata": {},
   "source": [
    "Because each commodity type and mode appears multiple times throughout the original DataFrame, to retrieve this aggregate information, we must use the .groupby(by=column) method. .groupby(by=column) returns a pairwise iterable of the unique values in the column with its associated subset DataFrames with all entries that share that same column value."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14038601",
   "metadata": {},
   "source": [
    "We'll start witih commodity types."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5528536",
   "metadata": {},
   "outputs": [],
   "source": [
    "groups_commodity = faf_data.groupby(by=\"Commodity Type\") # Returns an iterable of DataFrames, paired with name of commodity\n",
    "difference_comms = [] # Set up initial list of tuples for [(value, name),...], where value comes first to be sorted on.\n",
    "for name, group in groups_commodity:\n",
    "    print(name)\n",
    "    print(group.head())\n",
    "    comm_difference = group[\"Difference in Tons (2017 to 2050)\"].sum() # Sum of values for this subset DataFrame\n",
    "    difference_comms.append((comm_difference, name))\n",
    "difference_comms = sorted(difference_comms)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e87aac14",
   "metadata": {},
   "source": [
    "Now we'll index for our bottom 10 and top 10 commodity difference values and print out our results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54f005e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "bot_10_comm_diff = difference_comms[:10]\n",
    "top_10_comm_diff = difference_comms[::-1][:10] # [::-1] reverses list (walking backwards), providing list in descending order"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "567c5090",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Bottom 10 Differences in Tons from 2017 to 2050 by Commodity Type\")\n",
    "for diff, name in bot_10_comm_diff:\n",
    "    print(name + \": \" + \"{:,}\".format(round(diff, 3)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73582f0d",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "print(\"Top 10 Differences in Tons from 2017 to 2050 by Commodity Type\")\n",
    "for diff, name in top_10_comm_diff:\n",
    "    print(name + \": \" + \"{:,}\".format(round(diff, 3)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2261d7d7",
   "metadata": {},
   "source": [
    "Repeating the .groupby() to find out the total differences in modes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b30feb82",
   "metadata": {},
   "outputs": [],
   "source": [
    "groups_mode = faf_data.groupby(by=\"Mode\") # Returns an iterable of DataFrames, paired with name of commodity\n",
    "mode_differences = []\n",
    "\n",
    "for name, group in groups_mode:\n",
    "    mode_difference = group[\"Difference in Tons (2017 to 2050)\"].sum()\n",
    "    mode_differences.append((mode_difference, name))\n",
    "mode_differences = sorted(mode_differences)[::-1] # Descending order"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d78ac3e4",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "print(\"Differences in Tons from 2017 to 2050 by Mode\")\n",
    "for diff, name in mode_differences:\n",
    "    print(name + \": \" + \"{:,}\".format(round(diff, 3)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b933179",
   "metadata": {},
   "source": [
    "## Appendix: Basic Visualization with Matplotlib.pyplot and Pandas"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f88a65d7",
   "metadata": {},
   "source": [
    "#### First let's plot a horizontal bar chart visualizing the difference in tons from 2017 to 2050 by commodity type. We'll use Matplotlib's direct functionality for this because we have the data available in list form."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e62d0b9",
   "metadata": {},
   "source": [
    "Using the list of (tons, commodity) values generated from before, we'll call Matplotlib's .barh(y, x) method and related helper methods to edit the plot as desired. In practice, this takes some back-and-forth with documentation in order to achieve a \"pretty enough\" chart."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4fb1198b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set up the plot with desired figure size (width, height)\n",
    "fig, ax = plt.subplots(figsize=(11, 20))\n",
    "ax.set_title(\"Difference in Tons (2017 to 2050) by Commodity Type\")\n",
    "# Plot each bar with ax.barh(y, x)\n",
    "for data, comm in difference_comms:\n",
    "    ax.barh(comm, data, alpha=0.7)\n",
    "# Add labels specifying each value from ax.containers\n",
    "for container in ax.containers:\n",
    "    ax.bar_label(container, padding=2, fontsize=10, labels=[f'{x:,.0f}' for x in container.datavalues])\n",
    "# Extend the left of the chart for label fitting by inserting at the front\n",
    "x_ticks = ax.get_xticks()\n",
    "x_ticks = np.insert(x_ticks, 0, 2*x_ticks[0])\n",
    "ax.set_xticks(x_ticks)\n",
    "# Put a grid over the chart\n",
    "ax.grid(alpha=0.5)\n",
    "# Add labels along each axis\n",
    "ax.set_ylabel(\"Commodity Type\")\n",
    "ax.set_xlabel(\"Tons (10s of Millions)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6736bf8d",
   "metadata": {},
   "source": [
    "#### Next let's similarly plot a horizontal bar chart for difference in tons from 2017 to 2050 by mode."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "174f4d08",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(12, 6))\n",
    "ax.set_title(\"Difference in Tons (2017 to 2050) by Mode\")\n",
    "for data, mode in mode_differences[::-1]:\n",
    "    ax.barh(mode, data, alpha=0.5)\n",
    "for container in ax.containers:\n",
    "    ax.bar_label(container, padding=2, fontsize=10, labels=[f'{x:,.0f}' for x in container.datavalues])\n",
    "x_ticks = ax.get_xticks()\n",
    "## Extend the right-end of the ticks to fit our label\n",
    "x_ticks = np.append(ax.get_xticks(), [x_ticks[-1]+x_ticks[1]])\n",
    "ax.set_xticks(x_ticks)\n",
    "ax.grid(alpha=0.5)\n",
    "ax.set_ylabel(\"Mode\")\n",
    "ax.set_xlabel(\"Tons (10s of Millions)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f19a1df3",
   "metadata": {},
   "source": [
    "#### Let's also plot a grouped bar chart showing the trucks in 2017 versus trucks in 2050 by commodity type."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd09a125",
   "metadata": {},
   "source": [
    "This can be done with Pandas directly from the DataFrame, which uses plotting functionality from Matplotlib with some shorter syntax."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "77e36ba4",
   "metadata": {},
   "source": [
    "Since the previous lists we used for difference in tons for commodity type and mode were already in order, we will first need to sort the entries of the DataFrame, retrieve their indices in order with .index, and re-order the entries in a new DataFrame with .reindex(indices)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa2b46cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "in_order = faf_trucks[\"Trucks (2050)\"].sort_values().index\n",
    "faf_trucks_2 = faf_trucks.reindex(in_order)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe8fab31",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Plot the DataFrame directly using .plot(), and retrieve the figure object for further editing\n",
    "ax = faf_trucks_2.plot(x='Commodity Type', y=['Trucks (2017)', 'Trucks (2050)'], kind='barh', figsize=(10, 30), alpha=0.7)\n",
    "ax.set_title(\"Trucks in 2017 vs. 2050 by Commodity Type\")\n",
    "for container in ax.containers:\n",
    "    ax.bar_label(container, padding=2, fontsize=10, labels=[f'{x:,.0f}' for x in container.datavalues])\n",
    "x_ticks = ax.get_xticks()\n",
    "x_ticks = np.append(ax.get_xticks(), [x_ticks[-1]+x_ticks[1]])\n",
    "ax.set_xticks(x_ticks)\n",
    "ax.grid(alpha=0.5)\n",
    "ax.legend(loc=\"center right\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f6f9138",
   "metadata": {},
   "outputs": [],
   "source": [
    "in_order = faf_trucks[\"Difference in Trucks (2017 to 2050)\"].sort_values().index\n",
    "faf_trucks_2 = faf_trucks.reindex(in_order)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f774971c",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "ax = faf_trucks_2.plot(x='Commodity Type', y='Difference in Trucks (2017 to 2050)', kind=\"barh\", figsize=(10, 30), alpha=0.7)\n",
    "ax.set_title(\"Difference in Trucks from 2017 to 2050 by Commodity Type\")\n",
    "for container in ax.containers:\n",
    "    ax.bar_label(container, padding=2, fontsize=10, labels=[f'{x:,.0f}' for x in container.datavalues])\n",
    "x_ticks = ax.get_xticks()\n",
    "x_ticks = np.append(ax.get_xticks(), [x_ticks[-1]+x_ticks[1]])\n",
    "x_ticks = np.insert(x_ticks, 0, [(x_ticks[0]-x_ticks[1])*3])\n",
    "ax.set_xticks(x_ticks)\n",
    "ax.grid(alpha=0.5)\n",
    "ax.legend(loc=\"center right\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
